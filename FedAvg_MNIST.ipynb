{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9f6347",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Federated Learning from Scratch with PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568fe08",
   "metadata": {},
   "source": [
    "### Step 1: Setup and Data Preparation\n",
    "\n",
    "First, let's install PyTorch and prepare our data. Federated learning is all about distributed data, so we'll simulate this by splitting a single dataset (MNIST) into several smaller datasets, one for each \"client.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932a3fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import copy # We will use this to deep-copy our model to clients\n",
    "import random # For client selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e894887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a device for training (GPU if available, otherwise CPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16378630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transformations for our dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4cc99",
   "metadata": {},
   "source": [
    "#### Download and load the MNIST training and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2920a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a real-world scenario, this data would already be on the clients' devices.\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e4fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the number of clients we'll simulate\n",
    "NUM_CLIENTS = 10\n",
    "CLIENT_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc4c6a",
   "metadata": {},
   "source": [
    "#### Partition the data for each client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1e7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll split the training data equally among the 10 clients.\n",
    "client_data = torch.utils.data.random_split(train_dataset, \n",
    "                                            [len(train_dataset) // NUM_CLIENTS] * NUM_CLIENTS\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029b1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for each client's data\n",
    "client_trainloaders = [\n",
    "    DataLoader(data, batch_size=CLIENT_BATCH_SIZE, shuffle=True) for data in client_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304cd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single test DataLoader for the server's evaluation\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f940f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been partitioned among 10 clients.\n",
      "Each client has 6000 samples.\n",
      "Test dataset has 10000 samples.\n",
      "Test DataLoader created with batch size 128.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data has been partitioned among {NUM_CLIENTS} clients.\")\n",
    "print(f\"Each client has {len(client_data[0])} samples.\")\n",
    "print(f\"Test dataset has {len(test_dataset)} samples.\")\n",
    "print(f\"Test DataLoader created with batch size {test_dataloader.batch_size}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c148ee",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "torch, nn, optim: Standard PyTorch imports for building and training neural networks.\n",
    "\n",
    "copy: We'll use copy.deepcopy to create independent copies of the global model for each client.\n",
    "\n",
    "random: To randomly select a subset of clients for each training round.\n",
    "\n",
    "datasets.MNIST: We use the MNIST dataset because it's simple and a great starting point.\n",
    "\n",
    "torch.utils.data.random_split: This function is our \"magic wand\" for simulating decentralized data. It splits the train_dataset into 10 non-overlapping subsets, each representing a single client's private data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b23b62",
   "metadata": {},
   "source": [
    "## Step 2: Defining the Neural Network Model\n",
    "\n",
    "We'll use a simple Multi-Layer Perceptron (MLP) for this task. The model is defined once and will be used by both the server (as the global model) and the clients (as their local models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858427d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # 28x28 images, so input size is 784\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10) # Output layer for 10 classes (digits 0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32a5d52",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "This is a standard PyTorch nn.Module class. It defines the structure of our model.\n",
    "\n",
    "The forward method specifies how data flows through the network.\n",
    "\n",
    "We're using a simple architecture: flatten the image, pass it through two fully connected layers with a ReLU activation, and a final layer for the 10 output classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02c0f5",
   "metadata": {},
   "source": [
    "## Step 3: The Client-side Training Loop\n",
    "\n",
    "Each client needs a function to perform local training. This function will take the client's data and the current global model, train it for a few epochs, and return the updated model parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac8f878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_training(model, trainloader, epochs=1):\n",
    "    \"\"\"\n",
    "    Performs a single round of local training on a client's data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The global model parameters from the server.\n",
    "        trainloader (DataLoader): The client's local data loader.\n",
    "        epochs (int): Number of local epochs to train for.\n",
    "\n",
    "    Returns:\n",
    "        OrderedDict: The updated state_dict (model parameters) after local training.\n",
    "    \"\"\"\n",
    "    # Create a local copy of the model\n",
    "    local_model = copy.deepcopy(model).to(DEVICE)\n",
    "    local_model.train()  # Set the model to training mode\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(local_model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = local_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return local_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c09053",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "client_training function: This simulates a single client.\n",
    "\n",
    "copy.deepcopy(model): This is crucial! Each client needs its own independent copy of the global model to train on. We don't want them to modify the global model directly.\n",
    "\n",
    "local_model.train(): Sets the model to training mode.\n",
    "\n",
    "criterion and optimizer: We use a standard loss function and optimizer for our local training.\n",
    "\n",
    "The inner for loop is a standard PyTorch training loop for one local epoch.\n",
    "\n",
    "The function returns the state_dict, which is a dictionary containing the updated model's parameters (weights and biases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525f708",
   "metadata": {},
   "source": [
    "## Step 4: The Server-side Aggregation\n",
    "\n",
    "The server's job is to collect the updated parameters from the clients and combine them. We will implement the most common aggregation algorithm, Federated Averaging (FedAvg). FedAvg calculates a weighted average of the client model parameters, where the weight is proportional to the size of the client's training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f498749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_parameters(client_updates):\n",
    "    \"\"\"\n",
    "    Aggregates parameters from multiple clients using FedAvg.\n",
    "\n",
    "    Args:\n",
    "        client_updates (list): A list of client state_dicts (parameters).\n",
    "\n",
    "    Returns:\n",
    "        OrderedDict: The aggregated global state_dict.\n",
    "    \"\"\"\n",
    "\n",
    "    if not client_updates:\n",
    "        raise ValueError(\"No client updates provided for aggregation.\")\n",
    "        return None\n",
    "    \n",
    "    # We assume all clients have the same number of data points for simplicity\n",
    "    # In a real-world scenario, you would use weights based on data size.\n",
    "    global_state_dict = copy.deepcopy(client_updates[0])  # Start with the first client's parameters\n",
    "\n",
    "    for name in global_state_dict:\n",
    "        # Average the parameters across clients\n",
    "        global_state_dict[name] = torch.zero_like(global_state_dict[name])\n",
    "\n",
    "    for client_state_dict in client_updates:\n",
    "        for name, param in client_state_dict.items():\n",
    "            global_state_dict[name] += param / len(client_updates)\n",
    "\n",
    "    return global_state_dict\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd60feef",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "The aggregate_parameters function takes a list of state_dicts from the clients.\n",
    "\n",
    "It initializes a new dictionary (global_state_dict) with zeros.\n",
    "\n",
    "It then iterates through each client's state_dict and adds its parameters to the new global dictionary.\n",
    "\n",
    "Finally, it divides by the number of clients to get the average. For simplicity, we are assuming each client has the same amount of data, so it's a simple average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b4e16",
   "metadata": {},
   "source": [
    "## Step 5: The Federated Training Loop\n",
    "\n",
    "Now we put all the pieces together in a main loop that simulates the federated training process over multiple rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b66d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_evaluation(model, dataloader):\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluates the global model on the server's test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The global model to evaluate.\n",
    "        dataloader (DataLoader): The test dataset DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d315920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model initialized on the server.\n",
      "initial global model accuracy: 14.98%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the global model on the server\n",
    "global_model = MLP().to(DEVICE)\n",
    "print(\"Global model initialized on the server.\")\n",
    "print(f\"initial global model accuracy: {server_evaluation(global_model, test_dataloader):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa780b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Learning Main Loop\n",
    "NUM_ROUNDS = 5\n",
    "CLIENTS_PER_ROUND = 5 # Number of clients to select for each round\n",
    "\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "    print(f\"\\n--- Starting Federated Learning Round {round_num + 1}/{NUM_ROUNDS} ---\")\n",
    "\n",
    "    # 1. Server selects a subset of clients for the current round\n",
    "    participating_clients_indices = random.sample(range(NUM_CLIENTS), CLIENTS_PER_ROUND)\n",
    "    print(f\"Server selects clients: {participating_clients_indices}\")\n",
    "\n",
    "    # 2. Server sends the global model to the selected clients\n",
    "    client_updates = []\n",
    "\n",
    "    for client_idx in participating_clients_indices:\n",
    "        # Simulate local training on each client\n",
    "        print(f\"Client {client_idx} is training...\")\n",
    "        client_dataloader = client_trainloaders[client_idx]\n",
    "        local_state_dict = client_training(global_model, client_dataloader, epochs=1)\n",
    "        client_updates.append(local_state_dict)\n",
    "\n",
    "    # 3. Server aggregates the updates from all the participating clients\n",
    "    new_global_state_dict = aggregate_parameters(client_updates)\n",
    "    print(f\"Global model parameters Aggregated.\")\n",
    "\n",
    "    # 4. Server updates the global model with the aggregated parameters\n",
    "    if new_global_state_dict is not None:\n",
    "        global_model.load_state_dict(new_global_state_dict)\n",
    "        print(f\"Global model parameters updated.\")\n",
    "\n",
    "    # 5. Evaluate the updated global model on the server's test dataset\n",
    "    accuracy = server_evaluation(global_model, test_dataloader)\n",
    "    print(f\"Global model accuracy after round {round_num + 1}: {accuracy:.2f}%\")\n",
    "    print(\"Round completed.\\n\")\n",
    "\n",
    "print(\"\\n--- Federated Learning Finished ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UPFall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
